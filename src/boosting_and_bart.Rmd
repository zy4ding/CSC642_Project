---
title: "CSC642_proj"
author: "Ziyi Ding"
date: "2024-03-20"
output: html_document
---

# Data Processe

```{r}
library(dplyr)
library(readr)

flir <- read_csv("FLIR_data.csv")[,2:36] %>%
  as.data.frame() %>%
  na.omit() %>%
  mutate(
    Age = ifelse(Age=="21-25"|Age=="26-30","21-30",Age),
    Age = as.factor(Age),
    Gender = as.factor(Gender),
    Ethnicity = as.factor(Ethnicity))

set.seed(123)

n <- nrow(flir)
train.indices <- sample(1:n, size = floor(0.6 * n))
train.data <- flir[train.indices, ]
test.data <- flir[-train.indices, ]
```

# Boosting

```{r}
library(gbm)
library(ggplot2)

set.seed(123)
boost.m1 <- gbm(aveOralF ~. - aveOralM,data = train.data, distribution = "gaussian",
                n.trees = 5000, interaction.depth = 4, shrinkage = 0.001, verbose = F, cv.folds = 10)
boost.m2 <- gbm(aveOralM ~. - aveOralF,data = train.data, distribution = "gaussian",
                n.trees = 5000, interaction.depth = 4, shrinkage = 0.001, verbose = F, cv.folds = 10)

par(mfrow = c(1,2))
summary(boost.m1)
summary(boost.m2)


# RMSE of CV
yhat.boost1 <- predict(boost.m1, newdata = test.data, n.trees = 5000)
yhat.boost2 <- predict(boost.m2, newdata = test.data, n.trees = 5000)
mean((yhat.boost1 - test.data$aveOralF)^2)
mean((yhat.boost2 - test.data$aveOralM)^2)


# Influence variable plot
importance.m1 <- summary(boost.m1, n.trees = 5000, plot = FALSE)
importance.m2 <- summary(boost.m2, n.trees = 5000, plot = FALSE)

importance.df.m1 <- data.frame(Variable = rownames(importance.m1), Importance = importance.m1$rel.inf)
importance.df.m2 <- data.frame(Variable = rownames(importance.m2), Importance = importance.m2$rel.inf)

importance.df.m1$model <- 'aveOralF'
importance.df.m2$model <- 'aveOralM'

combined.importance.df <- rbind(importance.df.m1, importance.df.m2)

ggplot(combined.importance.df, aes(x = reorder(Variable, Importance), y = Importance, fill = model)) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_flip() + 
  labs(title = "Variable Importance for Boosting", x = "Variable", y = "Relative Importance") +
  scale_fill_brewer(palette = "Set1", name = "") +
  theme_minimal() +
  theme(legend.title = element_blank(), legend.position = "top")


# Partial dependence plots
calculate.pdp <- function(model, data, var.name, n.points = 100) {
  var.range <- range(data[[var.name]], na.rm = TRUE)
  var.seq <- seq(from = var.range[1], to = var.range[2], length.out = n.points)
  
  pd.data <- data.frame()
  for (val in var.seq) {
    modified.data <- data
    modified.data[[var.name]] <- val
    pred <- predict(model, newdata = modified.data, n.trees = 5000, type = "response")
    pd.data <- rbind(pd.data, data.frame(VarValue = val, Prediction = mean(pred)))
  }
  return(pd.data)
}

pdp.data1 <- calculate.pdp(boost.m1, train.data, "T_Max1")
pdp.data2 <- calculate.pdp(boost.m2, train.data, "T_Max1")
pdp.data1$Model <- "aveOralF"
pdp.data2$Model <- "aveOralM"

combined.pdp.data <- rbind(pdp.data1, pdp.data2)

ggplot(combined.pdp.data, aes(x = VarValue, y = Prediction, color = Model)) +
  geom_line() +
  ggtitle("Partial Dependence Plot for T_Max1") +
  xlab("T_Max1") +
  ylab("Partial Dependence") +
  scale_color_manual(values = c("aveOralF" = "red", "aveOralM" = "blue")) +
  theme_minimal()
```

# Bayesian Additive Regression Trees (BART)

```{r}
library(BART)

set.seed(123) 

flir.dat <- flir
flir.dat$Age <- as.numeric(flir.dat$Age) - 1
flir.dat$Humidity <- as.numeric(flir.dat$Humidity) - 1
flir.dat$Gender <- as.numeric(flir.dat$Gender) - 1
flir.dat$Ethnicity <- as.numeric(flir.dat$Ethnicity) - 1
  
x.full <- flir.dat[,-c(28:29)]
y.train1 <- flir.dat$aveOralF
y.train2 <- flir.dat$aveOralM

# Number of folds for cross-validation
k <- 10

# Initialize vectors to store results
cv.results1 <- vector("list", k)
cv.results2 <- vector("list", k)

# Cross-validation setup
folds <- cut(seq(1, nrow(x.full)), breaks = k, labels = FALSE)

for(i in 1:k){
  # Indices for the test fold
  test.indices <- which(folds == i, arr.ind = TRUE)
  # Indices for the training folds
  train.indices <- setdiff(seq(1, nrow(x.full)), test.indices)
  
  x.cv.train <- x.full[train.indices, ]
  y.cv.train1 <- y.train1[train.indices]
  y.cv.train2 <- y.train2[train.indices]
  
  x.cv.test <- x.full[test.indices, ]
  y.cv.test1 <- y.train1[test.indices]
  y.cv.test2 <- y.train2[test.indices]
  
  # Train BART models on the cv training set
  bart.m1 <- wbart(x.cv.train, y.cv.train1, x.cv.test)
  bart.m2 <- wbart(x.cv.train, y.cv.train2, x.cv.test)
  
  # Predictions for the cv test set
  predictions1 <- predict(bart.m1, x.cv.test)
  predictions2 <- predict(bart.m2, x.cv.test)
  
  # Store the predictions (or any other metric of interest)
  cv.results1[[i]] <- predictions1
  cv.results2[[i]] <- predictions2
}


# RMSE of CV
cv.results1[[1]] <- cv.results1[[1]][,2:101]
cv.results2[[1]] <- cv.results2[[1]][,2:101]
cv.dat1 <- do.call(rbind, cv.results1)
cv.dat2 <- do.call(rbind, cv.results2)

cv.mean1 <- colMeans(cv.dat1)
cv.mean2 <- colMeans(cv.dat2)

mean((cv.mean1 - y.cv.test1)^2)
mean((cv.mean2 - y.cv.test2)^2)

# Percentages of each variable used by the BART plot
percount.1 <- bart.m1$varcount/apply(bart.m1$varcount, 1, sum)
percount.2 <- bart.m2$varcount/apply(bart.m2$varcount, 1, sum)

# mean of row percentages
mvp.1 <- apply(percount.1, 2, mean)
mvp.2 <- apply(percount.2, 2, mean)

# quantiles of row percentags
qm.1 <- apply(percount.1, 2, quantile, probs = c(.05,.95))
qm.2 <- apply(percount.2, 2, quantile, probs = c(.05,.95))

p <- 33
rgy.1 <- range(qm.1)
rgy.2 <- range(qm.2)

df.m1 <- data.frame(Variable = var.names,
                    Importance = mvp.1,
                    Lower = qm.1[1, ],
                    Upper = qm.1[2, ],
                    Model = "aveOralF")

df.m2 <- data.frame(Variable = var.names,
                    Importance = mvp.2,
                    Lower = qm.2[1, ],
                    Upper = qm.2[2, ],
                    Model = "aveOralM")

combined.df <- rbind(df.m1, df.m2)

# Plot using ggplot2
ggplot(combined.df, aes(x = Variable, y = Importance, color = Model)) +
  geom_line(aes(group = Model), position = position_dodge(width = 0.25)) +
  geom_point(position = position_dodge(width = 0.25)) +
  coord_flip() + 
  labs(x = "Variable", y = "Post Mean, Percent Var Use",
       title = "Variable Importance in BART Models") +
  theme_minimal() +
  scale_color_manual(values = c("aveOralF" = "red", "aveOralM" = "blue")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.title = element_blank())
```


# Conclusion